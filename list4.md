1. #### Make an Gradio app that would turn speech(recording) into an image using [Whisper](https://github.com/openai/whisper) and [Stable Diffusion](https://github.com/CompVis/stable-diffusion)<br /> The gradio app would record the speech of the user(the user would describe the image using his voice), feed it into the Whisper model, the Whisper model would convert the speech into text and then the text would be feed into the stable-diffusion model which would make an image from the text input.)<br /> A user would generate an image using the app by describing the image using his voice. Whisper's translation feature allows for input in any supported language to be translated into english that Stable Diffusion supports. So the user can speak in a different language than english. Implemented in [Whisper+Stable_Diffusion.ipynb](https://github.com/sliscak/notebooks/blob/main/Whisper%2BStable_Diffusion.ipynb)
2. #### Replace Stable Diffusion in [Whisper+Stable_Diffusion.ipynb](https://github.com/sliscak/notebooks/blob/main/Whisper%2BStable_Diffusion.ipynb) with [Optimized Stable Diffusion](https://github.com/basujindal/stable-diffusion/tree/main/optimizedSD) 
3. #### Make an Gradio app(or notebook) that would turn text into a 3D mesh/model using [Stable Diffusion](https://github.com/CompVis/stable-diffusion) to turn text into a image and [Dense Prediction Transformer (DPT)](https://huggingface.co/Intel/dpt-large) to compute a depth map from the image and then use the depth map with the image to compute a 3D mesh(object).
4. #### Make an Gradio app(or notebook) that would turn a text description of a person into a 3D mesh/model using [Stable Diffusion](https://github.com/CompVis/stable-diffusion) to turn text description of a person into a image(of the person) and then [ClothWild](https://github.com/hygenie1228/ClothWild_RELEASE) would reconstruct robust 3D clothed humans from the generated image.
