1. #### Train [Whisper](https://github.com/openai/whisper) on EEG spectrogram and text(or label) pair datasets(like [MindBigData "IMAGENET"]([http://www.mindbigdata.com/](http://www.mindbigdata.com/opendb/imagenet.html))), to turn EEG spectrograms into text(or labels) (thoughts to text). Use the guide from https://huggingface.co/blog/fine-tune-whisper to train Whisper. The model would be used to decode EEG spectrograms into text(or labels).
2. #### Make an Gradio app(or notebook) that would turn text(description) into a 3D mesh/model using [Stable Diffusion](https://github.com/CompVis/stable-diffusion) to turn text into a image and [Dense Prediction Transformer (DPT)](https://huggingface.co/Intel/dpt-large) to compute a depth map from the image and then use [open3d](www.open3d.org) to compute a 3D mesh(object) from the depth map and the image. The image to 3D object using DPT(and open3d) idea is from https://huggingface.co/spaces/radames/dpt-depth-estimation-3d-obj, the only difference would be to use stable diffusion to generate the input image. 
