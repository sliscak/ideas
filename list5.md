1. #### Train [Whisper](https://github.com/openai/whisper) on EEG spectrogram and text(or label) pair datasets(like [MindBigData "IMAGENET"]([http://www.mindbigdata.com/](http://www.mindbigdata.com/opendb/imagenet.html))), to turn EEG spectrograms into text(or labels) (thoughts to text). Use the guide from https://huggingface.co/blog/fine-tune-whisper to train Whisper. The model would be used to decode EEG spectrograms into text(or labels).
2. #### Make an Gradio app(or notebook) that would turn text(description) into a 3D mesh/model using [Stable Diffusion](https://github.com/CompVis/stable-diffusion) to turn text into a image and [Dense Prediction Transformer (DPT)](https://huggingface.co/Intel/dpt-large) to compute a depth map from the image and then use [open3d](www.open3d.org) to compute a 3D mesh(object) from the depth map and the image. The image to 3D object using DPT(and open3d) idea is from https://huggingface.co/spaces/radames/dpt-depth-estimation-3d-obj, the only difference would be to use stable diffusion to generate the input image. 
3. #### Make an 3D RPG or MMORPG(role playing game)(in Godot or Unreal Engine 5) that that would generate 3D assets on the fly (continuously) using [Stable-DreamFusion](https://github.com/ashawkey/stable-dreamfusion). The map would be dynamic and populated on the fly with the generated 3D assets, the 3D assets could be generated (instanlty) on the fly or in advance on the client or server. The map creation would work like this: first a 2D or 3D map would be created by an algorithm like [WaveFunctionCollapse](https://github.com/mxgmn/WaveFunctionCollapse) or some other algorithm. The algorithm would place objects(like bridges, lanterns, fruits, people/npc's, etc) randomly or using the WaveFunctionCollapse either the on the fly generated 3D assets or it would place placeholder models that would be later replaced with the generated 3D models. Every model would have a name/noun and the description of the yet to be generated 3D model would be created, either with GPT3(or other pretrained language model) or by randomly sampling ajectives from a list of adjectives(like colros), the description would be build like this: "adjective adjective noun" -> "red wooden door". The description would be used as input into DreamFusion, DreamFusion would generate a 3D model from the text/description, the server would send the 3D model to the client (game) and the client would show the 3D model in the game.
4. ### Gradio APP: Speech (description) to 3D model using [Whisper](https://github.com/openai/whisper) and [Stable-DreamFusion](https://github.com/ashawkey/stable-dreamfusion). The gradio app records the speech/voice of the user, the uses the voice recording as input into Whisper, which transcribes the voice recording into english text(whisper also translates the text/recording into enlish in a single step). The text is then used as input into Stable-DreamFusion and Stable-DreamFusion generates a 3D model from the text. The app would show the 3D model in the UI to the user and offer to download the model by clicking on a download button.
